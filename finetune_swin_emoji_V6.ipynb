{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning ConvNeXtV2 with Binary Classifiers + XGBoost Ensemble (V6)\n",
    "\n",
    "Using one binary classifier per class, then XGBoost to vote between models.\n",
    "**Optimized for second dataset classes: Apple, Google, Facebook, Samsung**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install -q kagglehub transformers torch torchvision pillow datasets accelerate pandas scikit-learn xgboost\n",
    "\n",
    "import kagglehub\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import json\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from transformers.modeling_outputs import ImageClassifierOutput\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset as HFDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import pandas as pd\n",
    "import random\n",
    "import hashlib\n",
    "import xgboost as xgb\n",
    "\n",
    "# GPU Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"WARNING: CUDA not available. Training will be slow on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic Augmentation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unified Deterministic Augmentation System\n",
    "# Same augmentation methods used for both training and TTA inference\n",
    "# Deterministic based on image hash/index for reproducibility\n",
    "\n",
    "import hashlib\n",
    "\n",
    "class DeterministicAugmentation:\n",
    "    \"\"\"\n",
    "    Unified deterministic augmentation system for both training and TTA.\n",
    "    Uses the same augmentation methods, but deterministic based on image content.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_size=224, seed=42):\n",
    "        self.image_size = image_size\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Define augmentation parameters (same for training and TTA)\n",
    "        self.rotation_angles = [-10, -5, 5, 10]  # Fixed rotation angles\n",
    "        self.crop_ratios = [0.75, 0.85, 0.9, 0.95]  # Fixed crop ratios\n",
    "        self.color_jitter_params = {\n",
    "            'brightness': 0.3,\n",
    "            'contrast': 0.3,\n",
    "            'saturation': 0.3,\n",
    "            'hue': 0.1\n",
    "        }\n",
    "        self.translate_range = (0.1, 0.1)\n",
    "        self.blur_sigma = (0.1, 0.5)\n",
    "        \n",
    "    def _get_deterministic_seed(self, image_or_hash):\n",
    "        \"\"\"Generate deterministic seed from image hash or index.\"\"\"\n",
    "        if isinstance(image_or_hash, Image.Image):\n",
    "            # Use image content hash\n",
    "            img_bytes = image_or_hash.tobytes()\n",
    "            hash_val = int(hashlib.md5(img_bytes).hexdigest()[:8], 16)\n",
    "        elif isinstance(image_or_hash, (str, int)):\n",
    "            # Use provided hash/index\n",
    "            hash_val = hash(str(image_or_hash)) & 0xFFFFFFFF\n",
    "        else:\n",
    "            hash_val = hash(str(image_or_hash)) & 0xFFFFFFFF\n",
    "        return hash_val\n",
    "    \n",
    "    def horizontal_flip(self, image, apply=True):\n",
    "        \"\"\"Deterministic horizontal flip.\"\"\"\n",
    "        if apply:\n",
    "            return F.hflip(image)\n",
    "        return image\n",
    "    \n",
    "    def rotation(self, image, angle):\n",
    "        \"\"\"Deterministic rotation.\"\"\"\n",
    "        return F.rotate(image, angle)\n",
    "    \n",
    "    def center_crop(self, image, crop_ratio=0.9):\n",
    "        \"\"\"Deterministic center crop.\"\"\"\n",
    "        w, h = image.size\n",
    "        crop_size = int(min(w, h) * crop_ratio)\n",
    "        return F.center_crop(image, [crop_size, crop_size])\n",
    "    \n",
    "    def corner_crop(self, image, crop_ratio=0.9, position='tl'):\n",
    "        \"\"\"Deterministic corner crop (top-left, top-right, bottom-left, bottom-right).\"\"\"\n",
    "        w, h = image.size\n",
    "        crop_size = int(min(w, h) * crop_ratio)\n",
    "        \n",
    "        if position == 'tl':  # Top-left\n",
    "            return F.crop(image, 0, 0, crop_size, crop_size)\n",
    "        elif position == 'tr':  # Top-right\n",
    "            return F.crop(image, 0, w - crop_size, crop_size, crop_size)\n",
    "        elif position == 'bl':  # Bottom-left\n",
    "            return F.crop(image, h - crop_size, 0, crop_size, crop_size)\n",
    "        elif position == 'br':  # Bottom-right\n",
    "            return F.crop(image, h - crop_size, w - crop_size, crop_size, crop_size)\n",
    "        return image\n",
    "    \n",
    "    def resized_crop(self, image, crop_ratio=0.85):\n",
    "        \"\"\"Deterministic resized crop (simulating RandomResizedCrop).\"\"\"\n",
    "        w, h = image.size\n",
    "        crop_size = int(min(w, h) * crop_ratio)\n",
    "        # Use center crop as deterministic version\n",
    "        cropped = F.center_crop(image, [crop_size, crop_size])\n",
    "        return cropped.resize((self.image_size, self.image_size), Image.BILINEAR)\n",
    "    \n",
    "    def color_jitter(self, image, seed_val):\n",
    "        \"\"\"Deterministic color jitter based on seed.\"\"\"\n",
    "        # Use seed to deterministically select jitter parameters\n",
    "        np.random.seed(seed_val % (2**32))\n",
    "        brightness_factor = 1.0 + np.random.uniform(-self.color_jitter_params['brightness'], \n",
    "                                                      self.color_jitter_params['brightness'])\n",
    "        contrast_factor = 1.0 + np.random.uniform(-self.color_jitter_params['contrast'],\n",
    "                                                  self.color_jitter_params['contrast'])\n",
    "        saturation_factor = 1.0 + np.random.uniform(-self.color_jitter_params['saturation'],\n",
    "                                                     self.color_jitter_params['saturation'])\n",
    "        hue_factor = np.random.uniform(-self.color_jitter_params['hue'],\n",
    "                                      self.color_jitter_params['hue'])\n",
    "        \n",
    "        # Apply deterministic color jitter\n",
    "        img = F.adjust_brightness(image, brightness_factor)\n",
    "        img = F.adjust_contrast(img, contrast_factor)\n",
    "        img = F.adjust_saturation(img, saturation_factor)\n",
    "        img = F.adjust_hue(img, hue_factor)\n",
    "        return img\n",
    "    \n",
    "    def affine_transform(self, image, seed_val):\n",
    "        \"\"\"Deterministic affine transform (translation).\"\"\"\n",
    "        np.random.seed(seed_val % (2**32))\n",
    "        translate_x = np.random.uniform(-self.translate_range[0], self.translate_range[0])\n",
    "        translate_y = np.random.uniform(-self.translate_range[1], self.translate_range[1])\n",
    "        return F.affine(image, angle=0, translate=(translate_x * image.width, translate_y * image.height),\n",
    "                        scale=1.0, shear=0.0)\n",
    "    \n",
    "    def gaussian_blur(self, image, seed_val):\n",
    "        \"\"\"Deterministic Gaussian blur.\"\"\"\n",
    "        np.random.seed(seed_val % (2**32))\n",
    "        sigma = np.random.uniform(self.blur_sigma[0], self.blur_sigma[1])\n",
    "        return F.gaussian_blur(image, kernel_size=3, sigma=[sigma, sigma])\n",
    "    \n",
    "    def get_augmentations(self, image, num_augmentations=10, seed_source=None):\n",
    "        \"\"\"\n",
    "        Generate deterministic augmented versions for TTA.\n",
    "        Uses same augmentation methods as training.\n",
    "        \n",
    "        Args:\n",
    "            image: PIL Image\n",
    "            num_augmentations: Number of augmentations to generate\n",
    "            seed_source: Optional seed source (image hash, index, etc.) for determinism\n",
    "        \"\"\"\n",
    "        augmentations = []\n",
    "        \n",
    "        # Get deterministic seed\n",
    "        if seed_source is None:\n",
    "            seed_source = self._get_deterministic_seed(image)\n",
    "        seed_val = seed_source\n",
    "        \n",
    "        # Original (resized)\n",
    "        augmentations.append(image.resize((self.image_size, self.image_size), Image.BILINEAR))\n",
    "        \n",
    "        # Horizontal flip\n",
    "        flipped = self.horizontal_flip(image, apply=True)\n",
    "        augmentations.append(flipped.resize((self.image_size, self.image_size), Image.BILINEAR))\n",
    "        \n",
    "        # Rotations (deterministic angles)\n",
    "        for angle in self.rotation_angles[:min(4, num_augmentations - len(augmentations))]:\n",
    "            rotated = self.rotation(image, angle)\n",
    "            augmentations.append(rotated.resize((self.image_size, self.image_size), Image.BILINEAR))\n",
    "        \n",
    "        # Corner crops (4 corners)\n",
    "        corners = ['tl', 'tr', 'bl', 'br']\n",
    "        for corner in corners[:min(4, num_augmentations - len(augmentations))]:\n",
    "            cropped = self.corner_crop(image, crop_ratio=0.9, position=corner)\n",
    "            augmentations.append(cropped.resize((self.image_size, self.image_size), Image.BILINEAR))\n",
    "        \n",
    "        # Center crop\n",
    "        if len(augmentations) < num_augmentations:\n",
    "            center_cropped = self.center_crop(image, crop_ratio=0.9)\n",
    "            augmentations.append(center_cropped.resize((self.image_size, self.image_size), Image.BILINEAR))\n",
    "        \n",
    "        # Resized crop (simulating RandomResizedCrop)\n",
    "        if len(augmentations) < num_augmentations:\n",
    "            resized_cropped = self.resized_crop(image, crop_ratio=0.85)\n",
    "            augmentations.append(resized_cropped)\n",
    "        \n",
    "        # Color jitter\n",
    "        if len(augmentations) < num_augmentations:\n",
    "            jittered = self.color_jitter(image, seed_val)\n",
    "            augmentations.append(jittered.resize((self.image_size, self.image_size), Image.BILINEAR))\n",
    "        \n",
    "        # Affine transform\n",
    "        if len(augmentations) < num_augmentations:\n",
    "            affine_img = self.affine_transform(image, seed_val + 1)\n",
    "            augmentations.append(affine_img.resize((self.image_size, self.image_size), Image.BILINEAR))\n",
    "        \n",
    "        # Gaussian blur\n",
    "        if len(augmentations) < num_augmentations:\n",
    "            blurred = self.gaussian_blur(image, seed_val + 2)\n",
    "            augmentations.append(blurred.resize((self.image_size, self.image_size), Image.BILINEAR))\n",
    "        \n",
    "        return augmentations[:num_augmentations]\n",
    "    \n",
    "    def apply_training_augmentation(self, image, index=None):\n",
    "        \"\"\"\n",
    "        Apply deterministic training augmentation.\n",
    "        Uses same methods as TTA but applied once per training sample.\n",
    "        \n",
    "        Args:\n",
    "            image: PIL Image\n",
    "            index: Optional index for deterministic seed\n",
    "        \"\"\"\n",
    "        # Get deterministic seed from index or image\n",
    "        if index is not None:\n",
    "            seed_val = hash(str(index)) & 0xFFFFFFFF\n",
    "        else:\n",
    "            seed_val = self._get_deterministic_seed(image)\n",
    "        \n",
    "        # Apply augmentations deterministically based on seed\n",
    "        np.random.seed(seed_val % (2**32))\n",
    "        \n",
    "        # Horizontal flip (50% probability, but deterministic)\n",
    "        should_flip = (seed_val % 2 == 0)\n",
    "        if should_flip:\n",
    "            image = self.horizontal_flip(image, apply=True)\n",
    "        \n",
    "        # Rotation (deterministic angle selection)\n",
    "        angle_idx = (seed_val // 2) % len(self.rotation_angles)\n",
    "        angle = self.rotation_angles[angle_idx]\n",
    "        image = self.rotation(image, angle)\n",
    "        \n",
    "        # Resized crop (deterministic crop ratio)\n",
    "        crop_idx = (seed_val // 10) % len(self.crop_ratios)\n",
    "        crop_ratio = self.crop_ratios[crop_idx]\n",
    "        w, h = image.size\n",
    "        crop_size = int(min(w, h) * crop_ratio)\n",
    "        image = F.center_crop(image, [crop_size, crop_size])\n",
    "        \n",
    "        # Color jitter (deterministic)\n",
    "        image = self.color_jitter(image, seed_val)\n",
    "        \n",
    "        # Affine transform (deterministic, 50% probability)\n",
    "        if (seed_val // 3) % 2 == 0:\n",
    "            image = self.affine_transform(image, seed_val + 1)\n",
    "        \n",
    "        # Gaussian blur (deterministic, 20% probability)\n",
    "        if (seed_val // 5) % 5 == 0:\n",
    "            image = self.gaussian_blur(image, seed_val + 2)\n",
    "        \n",
    "        # Resize to final size\n",
    "        image = image.resize((self.image_size, self.image_size), Image.BILINEAR)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Create global augmentation instance\n",
    "augmentation_system = DeterministicAugmentation(image_size=224, seed=42)\n",
    "\n",
    "# For backward compatibility\n",
    "EnhancedTTAAugmentation = DeterministicAugmentation\n",
    "TTAAugmentation = DeterministicAugmentation\n",
    "\n",
    "# Training transform using deterministic augmentation\n",
    "# This will be applied in EmojiDataset using the augmentation_system\n",
    "train_transform = None  # Will use augmentation_system.apply_training_augmentation instead\n",
    "\n",
    "print(\"Unified deterministic augmentation system defined!\")\n",
    "print(\"Same augmentation methods used for both training and TTA inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ConvNeXtV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")\n",
    "base_model = AutoModelForImageClassification.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")\n",
    "\n",
    "# Move model to GPU\n",
    "base_model = base_model.to(device)\n",
    "print(f\"ConvNeXtV2 model loaded and moved to {device}\")\n",
    "print(f\"Model config: {base_model.config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Vendor Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes optimized for second dataset\n",
    "# Second dataset has: [\"apple\", \"google\", \"whatsapp\", \"facebook\", \"samsung\", \"mozilla\", \"messenger\"]\n",
    "# After mapping: whatsapp/messenger → Facebook, mozilla → Google\n",
    "# Effective classes: Apple, Google, Facebook, Samsung\n",
    "\n",
    "SECOND_DATASET_CLASSES = [\"Apple\", \"Google\", \"Facebook\", \"Samsung\"]\n",
    "SECOND_DATASET_TO_IDX = {vendor: idx for idx, vendor in enumerate(SECOND_DATASET_CLASSES)}\n",
    "IDX_TO_SECOND_DATASET = {idx: vendor for vendor, idx in SECOND_DATASET_TO_IDX.items()}\n",
    "\n",
    "# Mapping from first dataset classes to second dataset classes\n",
    "FIRST_DATASET_CLASSES = [\n",
    "    \"Apple\", \"DoCoMo\", \"Facebook\", \"Gmail\", \"Google\", \"JoyPixels\",\n",
    "    \"KDDI\", \"Samsung\", \"SoftBank\", \"Twitter\", \"Windows\"\n",
    "]\n",
    "\n",
    "FIRST_TO_SECOND_MAPPING = {\n",
    "    \"Apple\": \"Apple\",\n",
    "    \"Google\": \"Google\", \n",
    "    \"Gmail\": \"Google\",  # Gmail is Google\n",
    "    \"Facebook\": \"Facebook\",\n",
    "    \"Samsung\": \"Samsung\",\n",
    "    # Map other classes to closest match\n",
    "    \"DoCoMo\": \"Samsung\",  # Japanese vendor → Samsung (both Asian)\n",
    "    \"KDDI\": \"Samsung\",    # Japanese vendor → Samsung\n",
    "    \"SoftBank\": \"Samsung\", # Japanese vendor → Samsung\n",
    "    \"JoyPixels\": \"Facebook\",  # Emoji provider → Facebook\n",
    "    \"Twitter\": \"Facebook\",     # Social media → Facebook\n",
    "    \"Windows\": \"Samsung\",    # Microsoft → Samsung (closest match)\n",
    "}\n",
    "\n",
    "# Use optimized classes for model\n",
    "VENDOR_CLASSES = SECOND_DATASET_CLASSES\n",
    "VENDOR_TO_IDX = SECOND_DATASET_TO_IDX\n",
    "IDX_TO_VENDOR = IDX_TO_SECOND_DATASET\n",
    "\n",
    "print(f\"Optimized for second dataset: {len(VENDOR_CLASSES)} classes\")\n",
    "print(f\"Target classes: {VENDOR_CLASSES}\")\n",
    "print(f\"\\nFirst dataset → Second dataset mapping:\")\n",
    "for first_class, second_class in FIRST_TO_SECOND_MAPPING.items():\n",
    "    print(f\"  {first_class} → {second_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmojiDataset(Dataset):\n",
    "    \"\"\"Dataset class with support for deterministic training-time augmentation.\"\"\"\n",
    "    def __init__(self, image_paths, labels, processor, use_augmentation=False, augmentation_system=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.processor = processor\n",
    "        self.use_augmentation = use_augmentation\n",
    "        self.augmentation_system = augmentation_system if augmentation_system is not None else globals().get('augmentation_system', None)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), color='white')\n",
    "\n",
    "        if self.use_augmentation:\n",
    "            aug_system = globals().get('augmentation_system', None)\n",
    "            if aug_system is not None:\n",
    "                image = aug_system.apply_training_augmentation(image, index=idx)\n",
    "\n",
    "        inputs = self.processor(image, return_tensors=\"pt\")\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "\n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification Model Definition (One per Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeXtV2ForBinaryClassification(nn.Module):\n",
    "    \"\"\"Binary classifier for a single vendor class.\"\"\"\n",
    "    def __init__(self, base_model_ref, hidden_size=None):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model_ref\n",
    "        \n",
    "        # Get the hidden size from the model config\n",
    "        if hidden_size is None:\n",
    "            if hasattr(base_model_ref.config, 'hidden_sizes'):\n",
    "                hidden_size = base_model_ref.config.hidden_sizes[-1]\n",
    "            elif hasattr(base_model_ref.config, 'hidden_size'):\n",
    "                hidden_size = base_model_ref.config.hidden_size\n",
    "            else:\n",
    "                hidden_size = 768  # Default for tiny model\n",
    "        \n",
    "        # Binary classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_size),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden_size // 2),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_size // 2, 1)  # Binary: output 1 value\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values, labels=None):\n",
    "        # Get features from ConvNeXtV2 backbone\n",
    "        # convnextv2 returns BaseModelOutputWithPoolingAndNoAttention\n",
    "        backbone_output = self.base_model.convnextv2(pixel_values)\n",
    "        \n",
    "        # Extract the last hidden state (feature map)\n",
    "        if hasattr(backbone_output, 'last_hidden_state'):\n",
    "            features = backbone_output.last_hidden_state\n",
    "        elif hasattr(backbone_output, 'pooler_output') and backbone_output.pooler_output is not None:\n",
    "            # Use pooled output if available\n",
    "            pooled_output = backbone_output.pooler_output\n",
    "        else:\n",
    "            # Fallback: try to get hidden states\n",
    "            if hasattr(backbone_output, 'hidden_states') and backbone_output.hidden_states is not None:\n",
    "                features = backbone_output.hidden_states[-1]\n",
    "            else:\n",
    "                raise ValueError(\"Could not extract features from ConvNeXtV2 backbone\")\n",
    "        \n",
    "        # Global average pooling: (B, C, H, W) -> (B, C)\n",
    "        if 'pooled_output' not in locals():\n",
    "            if len(features.shape) == 4:\n",
    "                pooled_output = features.mean(dim=[2, 3])\n",
    "            else:\n",
    "                pooled_output = features\n",
    "\n",
    "        # Binary classification\n",
    "        logits = self.classifier(pooled_output)  # Shape: (B, 1)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # Binary cross entropy with logits\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.squeeze(-1), labels.float())\n",
    "\n",
    "        return ImageClassifierOutput(loss=loss, logits=logits)\n",
    "\n",
    "# Create one binary model per class\n",
    "binary_models = {}\n",
    "for vendor_idx, vendor_name in enumerate(VENDOR_CLASSES):\n",
    "    # Create a new base model instance for each binary classifier\n",
    "    model_base = AutoModelForImageClassification.from_pretrained(\"facebook/convnextv2-tiny-22k-224\")\n",
    "    model_base = model_base.to(device)\n",
    "    \n",
    "    binary_model = ConvNeXtV2ForBinaryClassification(model_base)\n",
    "    binary_model = binary_model.to(device)\n",
    "    binary_models[vendor_idx] = binary_model\n",
    "    print(f\"Created binary classifier for {vendor_name} (class {vendor_idx})\")\n",
    "\n",
    "print(f\"\\nTotal binary models created: {len(binary_models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_binary(model, train_loader, optimizer, device, scaler=None):\n",
    "    \"\"\"Train binary classifier for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    is_cuda_available = (device.type == 'cuda')\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        pixel_values = batch['pixel_values'].to(device, non_blocking=True)\n",
    "        labels = batch['labels'].to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast('cuda', enabled=is_cuda_available):\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # Binary prediction: sigmoid + threshold\n",
    "        probs = torch.sigmoid(outputs.logits.squeeze(-1))\n",
    "        predicted = (probs > 0.5).long()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return total_loss / len(train_loader), 100 * correct / total\n",
    "\n",
    "def validate_binary(model, val_loader, device):\n",
    "    \"\"\"Validate binary classifier.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    is_cuda_available = (device.type == 'cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            pixel_values = batch['pixel_values'].to(device, non_blocking=True)\n",
    "            labels = batch['labels'].to(device, non_blocking=True)\n",
    "\n",
    "            with torch.amp.autocast('cuda', enabled=is_cuda_available):\n",
    "                outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            probs = torch.sigmoid(outputs.logits.squeeze(-1))\n",
    "            predicted = (probs > 0.5).long()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return total_loss / len(val_loader), accuracy, all_probs, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTA Inference Functions (for final tests only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_binary_with_tta(model, image, processor, tta_aug, num_augmentations=10, device='cuda'):\n",
    "    \"\"\"Predict using binary classifier with TTA.\"\"\"\n",
    "    model.eval()\n",
    "    augmented_images = tta_aug.get_augmentations(image, num_augmentations=num_augmentations)\n",
    "    all_logits = []\n",
    "    weights = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, aug_image in enumerate(augmented_images):\n",
    "            inputs = processor(aug_image, return_tensors=\"pt\")\n",
    "            pixel_values = inputs['pixel_values'].to(device)\n",
    "            outputs = model(pixel_values=pixel_values)\n",
    "            logits = outputs.logits\n",
    "            all_logits.append(logits)\n",
    "            weight = 2.0 if i == 0 else 1.0\n",
    "            weights.append(weight)\n",
    "    \n",
    "    weights = torch.tensor(weights, device=device).view(-1, 1, 1)\n",
    "    weighted_logits = torch.stack(all_logits) * weights\n",
    "    averaged_logits = weighted_logits.sum(dim=0) / weights.sum()\n",
    "    probabilities = torch.sigmoid(averaged_logits.squeeze(-1))\n",
    "    \n",
    "    return probabilities.item()\n",
    "\n",
    "tta_aug = augmentation_system\n",
    "print(\"TTA inference functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Preparation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_path):\n",
    "    \"\"\"Prepare dataset by finding all images and mapping labels to second dataset classes.\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    dataset_path = Path(dataset_path)\n",
    "    image_extensions = {'.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'}\n",
    "\n",
    "    # First, collect all images with their original vendor labels\n",
    "    vendor_to_images = {}\n",
    "    for vendor in FIRST_DATASET_CLASSES:\n",
    "        vendor_dir = dataset_path / vendor\n",
    "        if vendor_dir.exists() and vendor_dir.is_dir():\n",
    "            for ext in image_extensions:\n",
    "                images = list(vendor_dir.glob(f\"*{ext}\"))\n",
    "                if vendor not in vendor_to_images:\n",
    "                    vendor_to_images[vendor] = []\n",
    "                vendor_to_images[vendor].extend([str(img_path) for img_path in images])\n",
    "\n",
    "    # If no vendor directories found, try filename/path matching\n",
    "    if len(vendor_to_images) == 0:\n",
    "        for ext in image_extensions:\n",
    "            all_images = list(dataset_path.rglob(f\"*{ext}\"))\n",
    "            for img_path in all_images:\n",
    "                filename = img_path.name.lower()\n",
    "                for vendor in FIRST_DATASET_CLASSES:\n",
    "                    if vendor.lower() in filename or vendor.lower() in str(img_path.parent).lower():\n",
    "                        if vendor not in vendor_to_images:\n",
    "                            vendor_to_images[vendor] = []\n",
    "                        vendor_to_images[vendor].append(str(img_path))\n",
    "                        break\n",
    "\n",
    "    # Map to second dataset classes\n",
    "    mapping_summary = {}\n",
    "    for original_vendor, img_list in vendor_to_images.items():\n",
    "        mapped_vendor = FIRST_TO_SECOND_MAPPING.get(original_vendor)\n",
    "        if mapped_vendor and mapped_vendor in VENDOR_CLASSES:\n",
    "            mapped_idx = VENDOR_TO_IDX[mapped_vendor]\n",
    "            for img_path in img_list:\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(mapped_idx)\n",
    "            mapping_summary[original_vendor] = (mapped_vendor, len(img_list))\n",
    "        else:\n",
    "            print(f\"WARNING: {original_vendor} → {mapped_vendor} not in target classes, skipping {len(img_list)} images\")\n",
    "\n",
    "    print(f\"\\nFirst dataset label mapping summary:\")\n",
    "    for original_vendor, (mapped_vendor, count) in mapping_summary.items():\n",
    "        print(f\"  {original_vendor} ({count} images) → {mapped_vendor}\")\n",
    "\n",
    "    return image_paths, labels\n",
    "\n",
    "def prepare_dataset_from_csv(train_dir, csv_path):\n",
    "    \"\"\"Prepare dataset by loading images and labels from CSV file.\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    train_dir = Path(train_dir)\n",
    "    csv_path = Path(csv_path)\n",
    "\n",
    "    if not csv_path.exists() or not train_dir.exists():\n",
    "        print(f\"WARNING: CSV or train directory not found\")\n",
    "        return image_paths, labels\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Mapping optimized for second dataset\n",
    "    explicit_mapping = {\n",
    "        'messenger': 'Facebook', \n",
    "        'whatsapp': 'Facebook', \n",
    "        'mozilla': 'Google'\n",
    "    }\n",
    "    unique_labels = df['Label'].str.lower().unique()\n",
    "    label_mapping = {}\n",
    "    \n",
    "    for csv_label in unique_labels:\n",
    "        matched = False\n",
    "        if csv_label in explicit_mapping:\n",
    "            mapped_vendor = explicit_mapping[csv_label]\n",
    "            if mapped_vendor in VENDOR_CLASSES:\n",
    "                label_mapping[csv_label.lower()] = VENDOR_TO_IDX[mapped_vendor]\n",
    "                matched = True\n",
    "        if not matched:\n",
    "            # Direct match with target classes\n",
    "            for vendor in VENDOR_CLASSES:\n",
    "                if csv_label == vendor.lower():\n",
    "                    label_mapping[csv_label.lower()] = VENDOR_TO_IDX[vendor]\n",
    "                    matched = True\n",
    "                    break\n",
    "        if not matched:\n",
    "            print(f\"WARNING: Label '{csv_label}' not found in target classes, skipping\")\n",
    "\n",
    "    skipped_count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        image_id = str(row['Id']).zfill(5)\n",
    "        label_str = str(row['Label']).lower()\n",
    "        \n",
    "        if label_str not in label_mapping:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        image_found = False\n",
    "        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "            image_path = train_dir / f\"{image_id}{ext}\"\n",
    "            if image_path.exists():\n",
    "                image_paths.append(str(image_path))\n",
    "                labels.append(label_mapping[label_str])\n",
    "                image_found = True\n",
    "                break\n",
    "        \n",
    "        if not image_found:\n",
    "            print(f\"WARNING: Image not found for ID {image_id}\")\n",
    "    \n",
    "    if skipped_count > 0:\n",
    "        print(f\"WARNING: Skipped {skipped_count} images due to unmapped labels\")\n",
    "    \n",
    "    print(f\"Loaded {len(image_paths)} images with {len(set(labels))} unique classes\")\n",
    "    if len(labels) > 0:\n",
    "        label_counts = np.bincount(labels)\n",
    "        print(f\"Label distribution: {label_counts}\")\n",
    "        # Show which classes are present\n",
    "        unique_label_indices = sorted(set(labels))\n",
    "        print(f\"Classes present: {[VENDOR_CLASSES[i] for i in unique_label_indices]}\")\n",
    "    \n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: First Dataset - Download and Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download first dataset\n",
    "path = kagglehub.dataset_download(\"subinium/emojiimage-dataset\")\n",
    "print(f\"Path to dataset files: {path}\")\n",
    "\n",
    "# Prepare dataset\n",
    "image_paths, labels = prepare_dataset(path)\n",
    "\n",
    "print(f\"\\nFound {len(image_paths)} images\")\n",
    "if len(labels) > 0:\n",
    "    print(f\"Labels distribution: {np.bincount(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Split First Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split first dataset into train and test\n",
    "if len(image_paths) > 0:\n",
    "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "        image_paths, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "    print(f\"Train samples: {len(train_paths)}\")\n",
    "    print(f\"Test samples: {len(test_paths)}\")\n",
    "    print(f\"Train label distribution: {np.bincount(train_labels)}\")\n",
    "    print(f\"Test label distribution: {np.bincount(test_labels)}\")\n",
    "else:\n",
    "    print(\"ERROR: No images found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Train Binary Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train one binary classifier per class\n",
    "if len(image_paths) > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training Binary Classifiers\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    batch_size = 16 if torch.cuda.is_available() else 8\n",
    "    num_epochs = 10\n",
    "    learning_rate = 1e-5\n",
    "    \n",
    "    # Mixed precision scaler\n",
    "    scaler = None\n",
    "    if torch.cuda.is_available():\n",
    "        model_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float32\n",
    "        if model_dtype == torch.float16:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # Train each binary classifier\n",
    "    for vendor_idx, vendor_name in enumerate(VENDOR_CLASSES):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Training binary classifier for {vendor_name} (Class {vendor_idx})\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Create binary labels: 1 if this class, 0 otherwise\n",
    "        binary_train_labels = [1 if label == vendor_idx else 0 for label in train_labels]\n",
    "        binary_test_labels = [1 if label == vendor_idx else 0 for label in test_labels]\n",
    "        \n",
    "        # Create datasets\n",
    "        binary_train_dataset = EmojiDataset(train_paths, binary_train_labels, processor, use_augmentation=True)\n",
    "        binary_test_dataset = EmojiDataset(test_paths, binary_test_labels, processor, use_augmentation=False)\n",
    "        \n",
    "        binary_train_loader = DataLoader(\n",
    "            binary_train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            num_workers=4 if torch.cuda.is_available() else 2,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        binary_test_loader = DataLoader(\n",
    "            binary_test_dataset, batch_size=batch_size, shuffle=False,\n",
    "            num_workers=4 if torch.cuda.is_available() else 2,\n",
    "            pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        # Get model and optimizer\n",
    "        model = binary_models[vendor_idx]\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='max', factor=0.5, patience=2, verbose=True, min_lr=1e-7\n",
    "        )\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        early_stopping_patience = 3\n",
    "        early_stopping_counter = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "            \n",
    "            train_loss, train_acc = train_epoch_binary(model, binary_train_loader, optimizer, device, scaler)\n",
    "            val_loss, val_acc, val_probs, val_labels_bin = validate_binary(model, binary_test_loader, device)\n",
    "            \n",
    "            scheduler.step(val_acc)\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                early_stopping_counter = 0\n",
    "                torch.save(model.state_dict(), f'best_binary_model_class_{vendor_idx}.pt')\n",
    "                print(f\"✓ Saved best model with validation accuracy: {best_val_acc:.2f}%\")\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                if early_stopping_counter >= early_stopping_patience:\n",
    "                    print(f\"Early stopping triggered!\")\n",
    "                    break\n",
    "        \n",
    "        # Load best model\n",
    "        if os.path.exists(f'best_binary_model_class_{vendor_idx}.pt'):\n",
    "            model.load_state_dict(torch.load(f'best_binary_model_class_{vendor_idx}.pt', map_location=device))\n",
    "        \n",
    "        print(f\"\\nCompleted training for {vendor_name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"All binary classifiers trained!\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"ERROR: Cannot train without data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from all binary models to use as features for XGBoost\n",
    "if len(image_paths) > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Generating Features from Binary Classifiers\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "def generate_binary_features(image_paths_list, labels_list, use_augmentation=False):\n",
    "        \"\"\"Generate features from all binary classifiers.\"\"\"\n",
    "        features = []\n",
    "        true_labels = []\n",
    "        \n",
    "        dataset = EmojiDataset(image_paths_list, labels_list, processor, use_augmentation=use_augmentation)\n",
    "        loader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "        \n",
    "        all_binary_probs = [[] for _ in range(len(VENDOR_CLASSES))]\n",
    "        \n",
    "        for batch in tqdm(loader, desc=\"Generating features\"):\n",
    "            pixel_values = batch['pixel_values'].to(device)\n",
    "            batch_labels = batch['labels'].cpu().numpy()\n",
    "            true_labels.extend(batch_labels)\n",
    "            \n",
    "            # Get predictions from all binary models\n",
    "            batch_features = []\n",
    "            for vendor_idx in range(len(VENDOR_CLASSES)):\n",
    "                model = binary_models[vendor_idx]\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(pixel_values=pixel_values)\n",
    "                    probs = torch.sigmoid(outputs.logits.squeeze(-1))\n",
    "                    batch_features.append(probs.cpu().numpy())\n",
    "            \n",
    "            # Stack features: (num_classes, batch_size) -> (batch_size, num_classes)\n",
    "            batch_features = np.stack(batch_features, axis=1)\n",
    "            features.extend(batch_features)\n",
    "        \n",
    "        return np.array(features), np.array(true_labels)\n",
    "    \n",
    "    # Generate features for train and test\n",
    "    print(\"Generating training features...\")\n",
    "    X_train, y_train = generate_binary_features(train_paths, train_labels, use_augmentation=False)\n",
    "    \n",
    "    print(\"Generating test features...\")\n",
    "    X_test, y_test = generate_binary_features(test_paths, test_labels, use_augmentation=False)\n",
    "    \n",
    "    print(f\"\\nTraining features shape: {X_train.shape}\")\n",
    "    print(f\"Training labels shape: {y_train.shape}\")\n",
    "    print(f\"Test features shape: {X_test.shape}\")\n",
    "    print(f\"Test labels shape: {y_test.shape}\")\n",
    "    print(f\"\\nFeature range: [{X_train.min():.4f}, {X_train.max():.4f}]\")\n",
    "else:\n",
    "    print(\"ERROR: Cannot generate features without data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost classifier on binary model outputs\n",
    "if len(image_paths) > 0 and 'X_train' in locals():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training XGBoost Ensemble\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # XGBoost parameters\n",
    "    xgb_params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(VENDOR_CLASSES),\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 200,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 0.1,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 1.0,\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist' if torch.cuda.is_available() else 'approx'\n",
    "    }\n",
    "    \n",
    "    # Create XGBoost classifier\n",
    "    xgb_classifier = xgb.XGBClassifier(**xgb_params)\n",
    "    \n",
    "    print(\"Training XGBoost...\")\n",
    "    xgb_classifier.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_pred = xgb_classifier.predict(X_train)\n",
    "    test_pred = xgb_classifier.predict(X_test)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, train_pred) * 100\n",
    "    test_acc = accuracy_score(y_test, test_pred) * 100\n",
    "    \n",
    "    print(f\"\\nXGBoost Training Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"XGBoost Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, test_pred, target_names=VENDOR_CLASSES))\n",
    "    \n",
    "    # Save XGBoost model\n",
    "    xgb_classifier.save_model('xgb_ensemble_model.json')\n",
    "    print(\"\\n✓ Saved XGBoost model to xgb_ensemble_model.json\")\n",
    "else:\n",
    "    print(\"ERROR: Cannot train XGBoost without features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Second Dataset - Load and Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second dataset (single path, no alternatives)\n",
    "dataset_base = Path(\"2-computer-vision-2025-b-sc-aidams-final-proj\")\n",
    "train_dir = dataset_base / \"train\"\n",
    "csv_path = dataset_base / \"train_labels.csv\"\n",
    "\n",
    "if not train_dir.exists():\n",
    "    print(f\"ERROR: Train directory not found at {train_dir}\")\n",
    "    print(\"Please ensure the dataset is in the correct location.\")\n",
    "    second_dataset_paths = []\n",
    "    second_dataset_labels = []\n",
    "else:\n",
    "    print(f\"Found train directory at: {train_dir}\")\n",
    "    print(f\"Found CSV file at: {csv_path}\")\n",
    "    \n",
    "    second_dataset_paths, second_dataset_labels = prepare_dataset_from_csv(train_dir, csv_path)\n",
    "    print(f\"\\nFound {len(second_dataset_paths)} labeled images from second dataset\")\n",
    "    \n",
    "    if len(second_dataset_paths) > 0:\n",
    "        print(f\"Label distribution: {np.bincount(second_dataset_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    xgb_params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(VENDOR_CLASSES),\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 200,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 0.1,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 1.0,\n",
    "        'random_state': 42,\n",
    "        'tree_method': 'hist' if torch.cuda.is_available() else 'approx'\n",
    "    }\n",
    "\n",
    "# Global XGBoost parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Re-fine-tune Binary Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fine-tune binary classifiers on second dataset\n",
    "if len(second_dataset_paths) > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Re-fine-tuning Binary Classifiers on Second Dataset\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Split second dataset with STRICT stratified sampling\n",
    "    if len(second_dataset_paths) > 100:\n",
    "        unique_labels, label_counts = np.unique(second_dataset_labels, return_counts=True)\n",
    "        min_class_count = label_counts.min()\n",
    "        \n",
    "        # Always try stratified split if possible\n",
    "        if min_class_count >= 2:\n",
    "            try:\n",
    "                second_train_paths, second_val_paths, second_train_labels, second_val_labels = train_test_split(\n",
    "                    second_dataset_paths, second_dataset_labels, test_size=0.1, random_state=42, stratify=second_dataset_labels\n",
    "                )\n",
    "                print(f\"✓ Split with STRATIFIED sampling: {len(second_train_paths)} train, {len(second_val_paths)} validation\")\n",
    "            except ValueError as e:\n",
    "                print(f\"⚠️ Stratification failed: {e}\")\n",
    "                # Fallback: still try to maintain some balance\n",
    "                second_train_paths, second_val_paths, second_train_labels, second_val_labels = train_test_split(\n",
    "                    second_dataset_paths, second_dataset_labels, test_size=0.1, random_state=42\n",
    "                )\n",
    "                print(f\"Split without stratification: {len(second_train_paths)} train, {len(second_val_paths)} validation\")\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Cannot stratify (min class count: {min_class_count} < 2)\")\n",
    "            second_train_paths, second_val_paths, second_train_labels, second_val_labels = train_test_split(\n",
    "                second_dataset_paths, second_dataset_labels, test_size=0.1, random_state=42\n",
    "            )\n",
    "        \n",
    "        print(f\"\\nTrain label distribution: {np.bincount(second_train_labels)}\")\n",
    "        print(f\"Validation label distribution: {np.bincount(second_val_labels)}\")\n",
    "    else:\n",
    "        second_train_paths, second_val_paths = second_dataset_paths, []\n",
    "        second_train_labels, second_val_labels = second_dataset_labels, []\n",
    "        print(\"Dataset too small for validation split, using all for training\")\n",
    "    \n",
    "    batch_size = 16 if torch.cuda.is_available() else 8\n",
    "    refinetune_epochs = 5\n",
    "    refinetune_lr = 5e-6\n",
    "    \n",
    "    scaler = None\n",
    "    if torch.cuda.is_available():\n",
    "        model_dtype = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float32\n",
    "        if model_dtype == torch.float16:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # Re-fine-tune each binary classifier\n",
    "    for vendor_idx, vendor_name in enumerate(VENDOR_CLASSES):\n",
    "        print(f\"\\nRe-fine-tuning binary classifier for {vendor_name}...\")\n",
    "        \n",
    "        # Load best model from phase 1\n",
    "        if os.path.exists(f'best_binary_model_class_{vendor_idx}.pt'):\n",
    "            binary_models[vendor_idx].load_state_dict(torch.load(f'best_binary_model_class_{vendor_idx}.pt', map_location=device))\n",
    "        \n",
    "        # Create binary labels\n",
    "        binary_train_labels = [1 if label == vendor_idx else 0 for label in second_train_labels]\n",
    "        \n",
    "        # Create dataset\n",
    "        binary_train_dataset = EmojiDataset(second_train_paths, binary_train_labels, processor, use_augmentation=True)\n",
    "        binary_train_loader = DataLoader(\n",
    "            binary_train_dataset, batch_size=batch_size, shuffle=True,\n",
    "            num_workers=4 if torch.cuda.is_available() else 2, pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        model = binary_models[vendor_idx]\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=refinetune_lr, weight_decay=0.01)\n",
    "        \n",
    "        for epoch in range(refinetune_epochs):\n",
    "            train_loss, train_acc = train_epoch_binary(model, binary_train_loader, optimizer, device, scaler)\n",
    "            if (epoch + 1) % 2 == 0:\n",
    "                print(f\"  Epoch {epoch + 1}/{refinetune_epochs}: Loss={train_loss:.4f}, Acc={train_acc:.2f}%\")\n",
    "        \n",
    "        torch.save(model.state_dict(), f'best_binary_model_class_{vendor_idx}_phase2.pt')\n",
    "    \n",
    "    print(\"\\n✓ All binary classifiers re-fine-tuned!\")\n",
    "    \n",
    "    # Re-train XGBoost on combined features\n",
    "    print(\"\\nRe-training XGBoost on combined dataset...\")\n",
    "    \n",
    "    # Generate features from second dataset for XGBoost (using train split only for now)\n",
    "    second_X, second_y = generate_binary_features(second_train_paths, second_train_labels, use_augmentation=False)\n",
    "    \n",
    "    # Combine with first dataset features\n",
    "    X_combined = np.vstack([X_train, second_X])\n",
    "    y_combined = np.hstack([y_train, second_y])\n",
    "    \n",
    "    # Re-train XGBoost\n",
    "    xgb_classifier = xgb.XGBClassifier(**xgb_params)\n",
    "    xgb_classifier.fit(X_combined, y_combined, eval_set=[(X_test, y_test)], verbose=True)\n",
    "    \n",
    "    test_pred = xgb_classifier.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, test_pred) * 100\n",
    "    print(f\"\\nXGBoost Test Accuracy after re-training: {test_acc:.2f}%\")\n",
    "    \n",
    "    xgb_classifier.save_model('xgb_ensemble_model_phase2.json')\n",
    "    print(\"✓ Saved updated XGBoost model\")\n",
    "else:\n",
    "    print(\"Skipping phase 2 (no second dataset found)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Final Training on Combined Train+Validation Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and validation for final training (no data leakage)\n",
    "if len(second_val_paths) > 0 and len(second_dataset_paths) > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Final Training on Combined Second Dataset (Train + Validation)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Combine splits\n",
    "    combined_second_train_paths = second_train_paths + second_val_paths\n",
    "    combined_second_train_labels = second_train_labels + second_val_labels\n",
    "    \n",
    "    print(f\"Combined second dataset: {len(combined_second_train_paths)} samples\")\n",
    "    print(f\"  - Original train: {len(second_train_paths)} samples\")\n",
    "    print(f\"  - Original validation: {len(second_val_paths)} samples\")\n",
    "    print(f\"Combined label distribution: {np.bincount(combined_second_train_labels)}\")\n",
    "    \n",
    "    # Re-fine-tune binary classifiers on combined data\n",
    "    for vendor_idx, vendor_name in enumerate(VENDOR_CLASSES):\n",
    "        print(f\"\\nFinal training binary classifier for {vendor_name}...\")\n",
    "        \n",
    "        # Load best model from phase 2\n",
    "        if os.path.exists(f'best_binary_model_class_{vendor_idx}_phase2.pt'):\n",
    "            binary_models[vendor_idx].load_state_dict(torch.load(f'best_binary_model_class_{vendor_idx}_phase2.pt', map_location=device))\n",
    "        elif os.path.exists(f'best_binary_model_class_{vendor_idx}.pt'):\n",
    "            binary_models[vendor_idx].load_state_dict(torch.load(f'best_binary_model_class_{vendor_idx}.pt', map_location=device))\n",
    "        \n",
    "        # Create binary labels for combined data\n",
    "        binary_combined_labels = [1 if label == vendor_idx else 0 for label in combined_second_train_labels]\n",
    "        \n",
    "        # Create dataset\n",
    "        binary_combined_dataset = EmojiDataset(combined_second_train_paths, binary_combined_labels, processor, use_augmentation=True)\n",
    "        binary_combined_loader = DataLoader(\n",
    "            binary_combined_dataset, batch_size=batch_size, shuffle=True,\n",
    "            num_workers=4 if torch.cuda.is_available() else 2, pin_memory=torch.cuda.is_available()\n",
    "        )\n",
    "        \n",
    "        model = binary_models[vendor_idx]\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=3e-6, weight_decay=0.01)\n",
    "        \n",
    "        for epoch in range(2):  # Short final training\n",
    "            train_loss, train_acc = train_epoch_binary(model, binary_combined_loader, optimizer, device, scaler)\n",
    "        \n",
    "        torch.save(model.state_dict(), f'best_binary_model_class_{vendor_idx}_final.pt')\n",
    "    \n",
    "    print(\"\\n✓ All binary classifiers final training completed!\")\n",
    "    \n",
    "    # Re-train XGBoost on final combined features\n",
    "    print(\"\\nRe-training XGBoost on final combined dataset...\")\n",
    "    combined_X, combined_y = generate_binary_features(combined_second_train_paths, combined_second_train_labels, use_augmentation=False)\n",
    "    \n",
    "    # Combine with first dataset\n",
    "    X_final = np.vstack([X_train, combined_X])\n",
    "    y_final = np.hstack([y_train, combined_y])\n",
    "    \n",
    "    xgb_classifier = xgb.XGBClassifier(**xgb_params)\n",
    "    xgb_classifier.fit(X_final, y_final, eval_set=[(X_test, y_test)], verbose=True)\n",
    "    \n",
    "    test_pred = xgb_classifier.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, test_pred) * 100\n",
    "    print(f\"\\nXGBoost Final Test Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    xgb_classifier.save_model('xgb_ensemble_model_final.json')\n",
    "    print(\"✓ Saved final XGBoost model\")\n",
    "else:\n",
    "    print(\"No validation split available for final training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions on Original Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original test data and generate predictions\n",
    "test_dataset_path = dataset_base / \"test\"\n",
    "\n",
    "if test_dataset_path.exists():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Generating Predictions on Original Test Data\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load best final models (trained on combined data)\n",
    "    for vendor_idx in range(len(VENDOR_CLASSES)):\n",
    "        if os.path.exists(f'best_binary_model_class_{vendor_idx}_final.pt'):\n",
    "            binary_models[vendor_idx].load_state_dict(torch.load(f'best_binary_model_class_{vendor_idx}_final.pt', map_location=device))\n",
    "        elif os.path.exists(f'best_binary_model_class_{vendor_idx}_phase2.pt'):\n",
    "            binary_models[vendor_idx].load_state_dict(torch.load(f'best_binary_model_class_{vendor_idx}_phase2.pt', map_location=device))\n",
    "        elif os.path.exists(f'best_binary_model_class_{vendor_idx}.pt'):\n",
    "            binary_models[vendor_idx].load_state_dict(torch.load(f'best_binary_model_class_{vendor_idx}.pt', map_location=device))\n",
    "    \n",
    "    # Load XGBoost model (prefer final model)\n",
    "    if os.path.exists('xgb_ensemble_model_final.json'):\n",
    "        xgb_classifier.load_model('xgb_ensemble_model_final.json')\n",
    "        print(\"Using final XGBoost model (trained on combined data)\")\n",
    "    elif os.path.exists('xgb_ensemble_model_phase2.json'):\n",
    "        xgb_classifier.load_model('xgb_ensemble_model_phase2.json')\n",
    "        print(\"Using phase 2 XGBoost model\")\n",
    "    elif os.path.exists('xgb_ensemble_model.json'):\n",
    "        xgb_classifier.load_model('xgb_ensemble_model.json')\n",
    "        print(\"Using phase 1 XGBoost model\")\n",
    "    \n",
    "    # Find test images\n",
    "    test_image_paths = []\n",
    "    image_extensions = {'.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'}\n",
    "    for ext in image_extensions:\n",
    "        test_image_paths.extend(list(test_dataset_path.rglob(f\"*{ext}\")))\n",
    "    test_image_paths = [str(p) for p in test_image_paths]\n",
    "    test_image_paths.sort()\n",
    "    \n",
    "    print(f\"Found {len(test_image_paths)} test images\")\n",
    "    \n",
    "    predictions = []\n",
    "    image_ids = []\n",
    "    \n",
    "    print(f\"Processing {len(test_image_paths)} test images with TTA...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image_path in tqdm(test_image_paths, desc=\"Generating predictions\"):\n",
    "            try:\n",
    "                image_id = Path(image_path).stem\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                \n",
    "                # Get predictions from all binary models with TTA\n",
    "                binary_features = []\n",
    "                for vendor_idx in range(len(VENDOR_CLASSES)):\n",
    "                    prob = predict_binary_with_tta(\n",
    "                        binary_models[vendor_idx], image, processor, tta_aug,\n",
    "                        num_augmentations=10, device=device\n",
    "                    )\n",
    "                    binary_features.append(prob)\n",
    "                \n",
    "                # Convert to numpy array and reshape for XGBoost\n",
    "                binary_features = np.array(binary_features).reshape(1, -1)\n",
    "                \n",
    "                # Predict with XGBoost\n",
    "                predicted_idx = xgb_classifier.predict(binary_features)[0]\n",
    "                \n",
    "                if predicted_idx >= len(VENDOR_CLASSES):\n",
    "                    print(f\"WARNING: Invalid prediction index {predicted_idx}, using first class\")\n",
    "                    predicted_idx = 0\n",
    "                \n",
    "                predicted_label = IDX_TO_VENDOR[predicted_idx]\n",
    "                predictions.append(predicted_label)\n",
    "                image_ids.append(image_id)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                predictions.append(VENDOR_CLASSES[0])\n",
    "                image_ids.append(Path(image_path).stem)\n",
    "    \n",
    "    # Create predictions.csv file\n",
    "    predictions_file = \"predictions.csv\"\n",
    "    with open(predictions_file, 'w') as f:\n",
    "        f.write(\"Id,Label\\n\")\n",
    "        for img_id, pred_label in zip(image_ids, predictions):\n",
    "            clean_id = str(img_id).strip()\n",
    "            f.write(f\"{clean_id},{pred_label}\\n\")\n",
    "    \n",
    "    print(f\"\\nPredictions saved to {predictions_file}\")\n",
    "    print(f\"Total predictions: {len(predictions)}\")\n",
    "    print(f\"Unique image IDs: {len(set(image_ids))}\")\n",
    "    \n",
    "    from collections import Counter\n",
    "    label_counts = Counter(predictions)\n",
    "    print(f\"\\nPrediction distribution:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        percentage = 100 * count / len(predictions)\n",
    "        print(f\"  {label}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    verification_df = pd.read_csv(predictions_file)\n",
    "    print(f\"\\nVerification - Loaded {len(verification_df)} rows from {predictions_file}\")\n",
    "    print(f\"Columns: {verification_df.columns.tolist()}\")\n",
    "    print(f\"\\nSample predictions:\")\n",
    "    print(verification_df.head(10))\n",
    "    \n",
    "    print(\"\\n✓ Predictions generation completed!\")\n",
    "else:\n",
    "    print(f\"Test directory not found at {test_dataset_path}\")\n",
    "    print(\"Cannot generate predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
