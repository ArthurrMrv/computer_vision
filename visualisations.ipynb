{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Second Dataset Analysis and Visualizations\n",
        "\n",
        "Comprehensive analysis of the second dataset to understand:\n",
        "- Label distribution\n",
        "- Image properties and their relationship to labels\n",
        "- Patterns in image IDs\n",
        "- Visual characteristics by class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install and Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install -q pandas pillow matplotlib seaborn numpy scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "import re\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Directory: data/train\n",
            "CSV File: data/train_labels.csv\n",
            "Test Directory: data/test\n"
          ]
        }
      ],
      "source": [
        "# Dataset paths\n",
        "SECOND_DATASET_BASE_PATH = \"data\"\n",
        "SECOND_DATASET_TRAIN_DIR = Path(SECOND_DATASET_BASE_PATH) / \"train\"\n",
        "SECOND_DATASET_CSV_PATH = Path(SECOND_DATASET_BASE_PATH) / \"train_labels.csv\"\n",
        "SECOND_DATASET_TEST_DIR = Path(SECOND_DATASET_BASE_PATH) / \"test\"\n",
        "\n",
        "print(f\"Train Directory: {SECOND_DATASET_TRAIN_DIR}\")\n",
        "print(f\"CSV File: {SECOND_DATASET_CSV_PATH}\")\n",
        "print(f\"Test Directory: {SECOND_DATASET_TEST_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load CSV with labels\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m SECOND_DATASET_CSV_PATH.exists():\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSECOND_DATASET_CSV_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded CSV with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.columns.tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Dev/youtube/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Dev/youtube/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Dev/youtube/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Dev/youtube/.venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Dev/youtube/.venv/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:574\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:663\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._get_header\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Load CSV with labels\n",
        "if SECOND_DATASET_CSV_PATH.exists():\n",
        "    df = pd.read_csv(SECOND_DATASET_CSV_PATH)\n",
        "    print(f\"Loaded CSV with {len(df)} rows\")\n",
        "    print(f\"Columns: {df.columns.tolist()}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df.head())\n",
        "    print(f\"\\nLabel value counts:\")\n",
        "    print(df['Label'].value_counts())\n",
        "else:\n",
        "    print(f\"ERROR: CSV file not found at {SECOND_DATASET_CSV_PATH}\")\n",
        "    df = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Image Properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cannot analyze images - dataset not found\n"
          ]
        }
      ],
      "source": [
        "def analyze_image_properties(image_path, image_id, label):\n",
        "    \"\"\"Extract properties from an image.\"\"\"\n",
        "    try:\n",
        "        image = Image.open(image_path)\n",
        "        \n",
        "        # Original mode\n",
        "        original_mode = image.mode\n",
        "        \n",
        "        # Handle palette images with transparency\n",
        "        if image.mode == 'P':\n",
        "            image = image.convert('RGBA')\n",
        "        # Convert to RGB, compositing transparent pixels onto white background\n",
        "        if image.mode == 'RGBA':\n",
        "            background = Image.new('RGB', image.size, (255, 255, 255))\n",
        "            background.paste(image, mask=image.split()[3])  # Use alpha channel as mask\n",
        "            image = background\n",
        "        elif image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "        \n",
        "        width, height = image.size\n",
        "        aspect_ratio = width / height if height > 0 else 0\n",
        "        \n",
        "        # Get image statistics\n",
        "        img_array = np.array(image)\n",
        "        mean_r = img_array[:, :, 0].mean()\n",
        "        mean_g = img_array[:, :, 1].mean()\n",
        "        mean_b = img_array[:, :, 2].mean()\n",
        "        std_r = img_array[:, :, 0].std()\n",
        "        std_g = img_array[:, :, 1].std()\n",
        "        std_b = img_array[:, :, 2].std()\n",
        "        \n",
        "        # Brightness (average of RGB)\n",
        "        brightness = (mean_r + mean_g + mean_b) / 3\n",
        "        \n",
        "        # Check if image is mostly white/light\n",
        "        is_mostly_white = brightness > 200\n",
        "        \n",
        "        # Extract numeric part from image_id if possible\n",
        "        image_id_numeric = None\n",
        "        try:\n",
        "            # Try to extract numbers from image_id\n",
        "            numbers = re.findall(r'\\d+', str(image_id))\n",
        "            if numbers:\n",
        "                image_id_numeric = int(numbers[0])\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        return {\n",
        "            'image_id': image_id,\n",
        "            'label': label,\n",
        "            'original_mode': original_mode,\n",
        "            'width': width,\n",
        "            'height': height,\n",
        "            'aspect_ratio': aspect_ratio,\n",
        "            'pixel_count': width * height,\n",
        "            'mean_r': mean_r,\n",
        "            'mean_g': mean_g,\n",
        "            'mean_b': mean_b,\n",
        "            'std_r': std_r,\n",
        "            'std_g': std_g,\n",
        "            'std_b': std_b,\n",
        "            'brightness': brightness,\n",
        "            'is_mostly_white': is_mostly_white,\n",
        "            'image_id_numeric': image_id_numeric\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Analyze all images\n",
        "if df is not None and SECOND_DATASET_TRAIN_DIR.exists():\n",
        "    print(\"\\nAnalyzing image properties...\")\n",
        "    image_data = []\n",
        "    \n",
        "    for idx, row in df.iterrows():\n",
        "        image_id = str(row['Id']).zfill(5)\n",
        "        label = str(row['Label']).lower()\n",
        "        \n",
        "        # Try to find image file\n",
        "        image_found = False\n",
        "        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
        "            image_path = SECOND_DATASET_TRAIN_DIR / f\"{image_id}{ext}\"\n",
        "            if image_path.exists():\n",
        "                props = analyze_image_properties(image_path, image_id, label)\n",
        "                if props:\n",
        "                    image_data.append(props)\n",
        "                image_found = True\n",
        "                break\n",
        "        \n",
        "        if not image_found and idx < 10:\n",
        "            print(f\"Warning: Image not found for ID {image_id}\")\n",
        "    \n",
        "    # Create DataFrame from image properties\n",
        "    image_df = pd.DataFrame(image_data)\n",
        "    print(f\"\\nAnalyzed {len(image_df)} images\")\n",
        "    print(f\"\\nImage properties DataFrame shape: {image_df.shape}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(image_df.head())\n",
        "else:\n",
        "    print(\"Cannot analyze images - dataset not found\")\n",
        "    image_df = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_df is not None and len(image_df) > 0:\n",
        "    # Label distribution\n",
        "    label_counts = image_df['label'].value_counts()\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Bar plot\n",
        "    axes[0].bar(label_counts.index, label_counts.values, color=sns.color_palette(\"husl\", len(label_counts)))\n",
        "    axes[0].set_xlabel('Label', fontsize=12)\n",
        "    axes[0].set_ylabel('Count', fontsize=12)\n",
        "    axes[0].set_title('Label Distribution (Count)', fontsize=14, fontweight='bold')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add count labels on bars\n",
        "    for i, (label, count) in enumerate(label_counts.items()):\n",
        "        axes[0].text(i, count, str(count), ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # Pie chart\n",
        "    axes[1].pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%', \n",
        "                colors=sns.color_palette(\"husl\", len(label_counts)), startangle=90)\n",
        "    axes[1].set_title('Label Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nLabel Distribution Summary:\")\n",
        "    print(label_counts)\n",
        "    print(f\"\\nTotal images: {len(image_df)}\")\n",
        "    print(f\"Number of unique labels: {len(label_counts)}\")\n",
        "    print(f\"\\nClass imbalance ratio (max/min): {label_counts.max() / label_counts.min():.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Image Size and Aspect Ratio Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_df is not None and len(image_df) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Width distribution by label\n",
        "    for label in image_df['label'].unique():\n",
        "        label_data = image_df[image_df['label'] == label]\n",
        "        axes[0, 0].hist(label_data['width'], alpha=0.6, label=label, bins=30)\n",
        "    axes[0, 0].set_xlabel('Width (pixels)', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
        "    axes[0, 0].set_title('Width Distribution by Label', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Height distribution by label\n",
        "    for label in image_df['label'].unique():\n",
        "        label_data = image_df[image_df['label'] == label]\n",
        "        axes[0, 1].hist(label_data['height'], alpha=0.6, label=label, bins=30)\n",
        "    axes[0, 1].set_xlabel('Height (pixels)', fontsize=12)\n",
        "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
        "    axes[0, 1].set_title('Height Distribution by Label', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "    \n",
        "    # Aspect ratio distribution by label\n",
        "    for label in image_df['label'].unique():\n",
        "        label_data = image_df[image_df['label'] == label]\n",
        "        axes[1, 0].hist(label_data['aspect_ratio'], alpha=0.6, label=label, bins=30)\n",
        "    axes[1, 0].set_xlabel('Aspect Ratio (width/height)', fontsize=12)\n",
        "    axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
        "    axes[1, 0].set_title('Aspect Ratio Distribution by Label', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(alpha=0.3)\n",
        "    \n",
        "    # Box plot: Aspect ratio by label\n",
        "    image_df.boxplot(column='aspect_ratio', by='label', ax=axes[1, 1])\n",
        "    axes[1, 1].set_xlabel('Label', fontsize=12)\n",
        "    axes[1, 1].set_ylabel('Aspect Ratio', fontsize=12)\n",
        "    axes[1, 1].set_title('Aspect Ratio by Label (Box Plot)', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Summary statistics\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Image Size Statistics by Label\")\n",
        "    print(\"=\"*70)\n",
        "    size_stats = image_df.groupby('label')[['width', 'height', 'aspect_ratio', 'pixel_count']].agg(['mean', 'std', 'min', 'max'])\n",
        "    print(size_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Color Analysis by Label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_df is not None and len(image_df) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Mean RGB values by label\n",
        "    rgb_means = image_df.groupby('label')[['mean_r', 'mean_g', 'mean_b']].mean()\n",
        "    \n",
        "    x = np.arange(len(rgb_means.index))\n",
        "    width = 0.25\n",
        "    \n",
        "    axes[0, 0].bar(x - width, rgb_means['mean_r'], width, label='Red', color='red', alpha=0.7)\n",
        "    axes[0, 0].bar(x, rgb_means['mean_g'], width, label='Green', color='green', alpha=0.7)\n",
        "    axes[0, 0].bar(x + width, rgb_means['mean_b'], width, label='Blue', color='blue', alpha=0.7)\n",
        "    axes[0, 0].set_xlabel('Label', fontsize=12)\n",
        "    axes[0, 0].set_ylabel('Mean RGB Value', fontsize=12)\n",
        "    axes[0, 0].set_title('Mean RGB Values by Label', fontsize=14, fontweight='bold')\n",
        "    axes[0, 0].set_xticks(x)\n",
        "    axes[0, 0].set_xticklabels(rgb_means.index, rotation=45)\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Brightness distribution by label\n",
        "    for label in image_df['label'].unique():\n",
        "        label_data = image_df[image_df['label'] == label]\n",
        "        axes[0, 1].hist(label_data['brightness'], alpha=0.6, label=label, bins=30)\n",
        "    axes[0, 1].set_xlabel('Brightness', fontsize=12)\n",
        "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
        "    axes[0, 1].set_title('Brightness Distribution by Label', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "    \n",
        "    # RGB standard deviation by label\n",
        "    rgb_stds = image_df.groupby('label')[['std_r', 'std_g', 'std_b']].mean()\n",
        "    \n",
        "    axes[1, 0].bar(x - width, rgb_stds['std_r'], width, label='Red Std', color='red', alpha=0.7)\n",
        "    axes[1, 0].bar(x, rgb_stds['std_g'], width, label='Green Std', color='green', alpha=0.7)\n",
        "    axes[1, 0].bar(x + width, rgb_stds['std_b'], width, label='Blue Std', color='blue', alpha=0.7)\n",
        "    axes[1, 0].set_xlabel('Label', fontsize=12)\n",
        "    axes[1, 0].set_ylabel('Mean RGB Standard Deviation', fontsize=12)\n",
        "    axes[1, 0].set_title('RGB Standard Deviation by Label', fontsize=14, fontweight='bold')\n",
        "    axes[1, 0].set_xticks(x)\n",
        "    axes[1, 0].set_xticklabels(rgb_stds.index, rotation=45)\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Mostly white images by label\n",
        "    white_by_label = image_df.groupby('label')['is_mostly_white'].agg(['sum', 'count'])\n",
        "    white_by_label['percentage'] = (white_by_label['sum'] / white_by_label['count']) * 100\n",
        "    \n",
        "    axes[1, 1].bar(white_by_label.index, white_by_label['percentage'], \n",
        "                  color=sns.color_palette(\"husl\", len(white_by_label)))\n",
        "    axes[1, 1].set_xlabel('Label', fontsize=12)\n",
        "    axes[1, 1].set_ylabel('Percentage of Mostly White Images (%)', fontsize=12)\n",
        "    axes[1, 1].set_title('Percentage of Mostly White Images by Label', fontsize=14, fontweight='bold')\n",
        "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Color Statistics by Label\")\n",
        "    print(\"=\"*70)\n",
        "    color_stats = image_df.groupby('label')[['mean_r', 'mean_g', 'mean_b', 'brightness']].agg(['mean', 'std'])\n",
        "    print(color_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Image ID Pattern Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Image Mode Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_df is not None and len(image_df) > 0:\n",
        "    # Analyze image ID patterns\n",
        "    image_df['image_id_length'] = image_df['image_id'].str.len()\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Image ID numeric distribution by label (if available)\n",
        "    if image_df['image_id_numeric'].notna().any():\n",
        "        for label in image_df['label'].unique():\n",
        "            label_data = image_df[(image_df['label'] == label) & (image_df['image_id_numeric'].notna())]\n",
        "            if len(label_data) > 0:\n",
        "                axes[0, 0].hist(label_data['image_id_numeric'], alpha=0.6, label=label, bins=50)\n",
        "        axes[0, 0].set_xlabel('Image ID (Numeric)', fontsize=12)\n",
        "        axes[0, 0].set_ylabel('Frequency', fontsize=12)\n",
        "        axes[0, 0].set_title('Image ID Numeric Distribution by Label', fontsize=14, fontweight='bold')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(alpha=0.3)\n",
        "    else:\n",
        "        axes[0, 0].text(0.5, 0.5, 'No numeric IDs found', ha='center', va='center', transform=axes[0, 0].transAxes)\n",
        "        axes[0, 0].set_title('Image ID Numeric Distribution', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Image ID length distribution\n",
        "    for label in image_df['label'].unique():\n",
        "        label_data = image_df[image_df['label'] == label]\n",
        "        axes[0, 1].hist(label_data['image_id_length'], alpha=0.6, label=label, bins=range(1, 20))\n",
        "    axes[0, 1].set_xlabel('Image ID Length', fontsize=12)\n",
        "    axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
        "    axes[0, 1].set_title('Image ID Length Distribution by Label', fontsize=14, fontweight='bold')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(alpha=0.3)\n",
        "    \n",
        "    # Scatter: Image ID numeric vs Label (if available)\n",
        "    if image_df['image_id_numeric'].notna().any():\n",
        "        label_unique = sorted(image_df['label'].unique())\n",
        "        for label in label_unique:\n",
        "            label_data = image_df[(image_df['label'] == label) & (image_df['image_id_numeric'].notna())]\n",
        "            if len(label_data) > 0:\n",
        "                axes[1, 0].scatter(label_data['image_id_numeric'], \n",
        "                                 [label_unique.index(label)] * len(label_data),\n",
        "                                 alpha=0.5, label=label, s=10)\n",
        "        axes[1, 0].set_xlabel('Image ID (Numeric)', fontsize=12)\n",
        "        axes[1, 0].set_ylabel('Label Index', fontsize=12)\n",
        "        axes[1, 0].set_title('Image ID vs Label (Scatter)', fontsize=14, fontweight='bold')\n",
        "        axes[1, 0].set_yticks(range(len(label_unique)))\n",
        "        axes[1, 0].set_yticklabels(label_unique)\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(alpha=0.3)\n",
        "    else:\n",
        "        axes[1, 0].text(0.5, 0.5, 'No numeric IDs found', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
        "        axes[1, 0].set_title('Image ID vs Label', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # Image ID range by label\n",
        "    if image_df['image_id_numeric'].notna().any():\n",
        "        id_ranges = image_df.groupby('label')['image_id_numeric'].agg(['min', 'max', 'mean'])\n",
        "        x_pos = np.arange(len(id_ranges))\n",
        "        axes[1, 1].bar(x_pos, id_ranges['max'] - id_ranges['min'], \n",
        "                      color=sns.color_palette(\"husl\", len(id_ranges)), alpha=0.7)\n",
        "        axes[1, 1].set_xlabel('Label', fontsize=12)\n",
        "        axes[1, 1].set_ylabel('ID Range (max - min)', fontsize=12)\n",
        "        axes[1, 1].set_title('Image ID Range by Label', fontsize=14, fontweight='bold')\n",
        "        axes[1, 1].set_xticks(x_pos)\n",
        "        axes[1, 1].set_xticklabels(id_ranges.index, rotation=45)\n",
        "        axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "    else:\n",
        "        axes[1, 1].text(0.5, 0.5, 'No numeric IDs found', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
        "        axes[1, 1].set_title('Image ID Range by Label', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Check if image IDs are predictive\n",
        "    if image_df['image_id_numeric'].notna().any():\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Image ID Statistics by Label\")\n",
        "        print(\"=\"*70)\n",
        "        id_stats = image_df.groupby('label')['image_id_numeric'].agg(['min', 'max', 'mean', 'std', 'count'])\n",
        "        print(id_stats)\n",
        "        \n",
        "        # Check for ID ranges that might indicate label\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Image ID Ranges by Label (Potential Pattern Detection)\")\n",
        "        print(\"=\"*70)\n",
        "        for label in image_df['label'].unique():\n",
        "            label_data = image_df[(image_df['label'] == label) & (image_df['image_id_numeric'].notna())]\n",
        "            if len(label_data) > 0:\n",
        "                print(f\"{label:15s}: IDs {label_data['image_id_numeric'].min():.0f} - {label_data['image_id_numeric'].max():.0f} (mean: {label_data['image_id_numeric'].mean():.1f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_df is not None and len(image_df) > 0:\n",
        "    # Image mode distribution\n",
        "    mode_counts = image_df['original_mode'].value_counts()\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Mode distribution overall\n",
        "    axes[0].bar(mode_counts.index, mode_counts.values, color=sns.color_palette(\"husl\", len(mode_counts)))\n",
        "    axes[0].set_xlabel('Image Mode', fontsize=12)\n",
        "    axes[0].set_ylabel('Count', fontsize=12)\n",
        "    axes[0].set_title('Image Mode Distribution (Overall)', fontsize=14, fontweight='bold')\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Mode distribution by label\n",
        "    mode_by_label = pd.crosstab(image_df['label'], image_df['original_mode'])\n",
        "    mode_by_label.plot(kind='bar', stacked=True, ax=axes[1], colormap='Set3')\n",
        "    axes[1].set_xlabel('Label', fontsize=12)\n",
        "    axes[1].set_ylabel('Count', fontsize=12)\n",
        "    axes[1].set_title('Image Mode Distribution by Label', fontsize=14, fontweight='bold')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "    axes[1].legend(title='Mode', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    axes[1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Image Mode Distribution by Label\")\n",
        "    print(\"=\"*70)\n",
        "    print(mode_by_label)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"Image Mode Percentages by Label\")\n",
        "    print(\"=\"*70)\n",
        "    mode_percentages = mode_by_label.div(mode_by_label.sum(axis=1), axis=0) * 100\n",
        "    print(mode_percentages.round(2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Correlation Analysis: Can We Predict Label from Image Properties?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_df is not None and len(image_df) > 0:\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import accuracy_score, classification_report\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    \n",
        "    # Prepare features\n",
        "    feature_cols = ['width', 'height', 'aspect_ratio', 'pixel_count', \n",
        "                   'mean_r', 'mean_g', 'mean_b', 'std_r', 'std_g', 'std_b', \n",
        "                   'brightness', 'is_mostly_white']\n",
        "    \n",
        "    if image_df['image_id_numeric'].notna().any():\n",
        "        feature_cols.append('image_id_numeric')\n",
        "    \n",
        "    # Remove rows with missing features\n",
        "    feature_df = image_df[feature_cols + ['label']].dropna()\n",
        "    \n",
        "    if len(feature_df) > 0:\n",
        "        X = feature_df[feature_cols]\n",
        "        y = feature_df['label']\n",
        "        \n",
        "        # Encode labels\n",
        "        le = LabelEncoder()\n",
        "        y_encoded = le.fit_transform(y)\n",
        "        \n",
        "        # Train a simple classifier to see if features are predictive\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "        \n",
        "        rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "        rf.fit(X_train, y_train)\n",
        "        \n",
        "        y_pred = rf.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Feature Importance Analysis\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"\\nCan we predict label from image properties?\")\n",
        "        print(f\"Random Forest Accuracy: {accuracy*100:.2f}%\")\n",
        "        print(f\"\\n(Note: This is just to see if properties are predictive, not a real model)\")\n",
        "        \n",
        "        # Feature importance\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': feature_cols,\n",
        "            'importance': rf.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        ax.barh(feature_importance['feature'], feature_importance['importance'], \n",
        "               color=sns.color_palette(\"husl\", len(feature_importance)))\n",
        "        ax.set_xlabel('Importance', fontsize=12)\n",
        "        ax.set_ylabel('Feature', fontsize=12)\n",
        "        ax.set_title('Feature Importance for Label Prediction', fontsize=14, fontweight='bold')\n",
        "        ax.grid(axis='x', alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print(\"\\nFeature Importance Ranking:\")\n",
        "        print(feature_importance)\n",
        "        \n",
        "        # Classification report\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"Classification Report (based on image properties only)\")\n",
        "        print(\"=\"*70)\n",
        "        print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "    else:\n",
        "        print(\"Not enough data with complete features for analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sample Images by Label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_df is not None and len(image_df) > 0 and SECOND_DATASET_TRAIN_DIR.exists():\n",
        "    # Show sample images from each label\n",
        "    n_samples_per_label = 4\n",
        "    unique_labels = sorted(image_df['label'].unique())\n",
        "    \n",
        "    fig, axes = plt.subplots(len(unique_labels), n_samples_per_label, figsize=(16, 4*len(unique_labels)))\n",
        "    \n",
        "    if len(unique_labels) == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "    \n",
        "    for label_idx, label in enumerate(unique_labels):\n",
        "        label_data = image_df[image_df['label'] == label].head(n_samples_per_label)\n",
        "        \n",
        "        for sample_idx, (_, row) in enumerate(label_data.iterrows()):\n",
        "            image_id = row['image_id']\n",
        "            \n",
        "            # Find image file\n",
        "            image_path = None\n",
        "            for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
        "                potential_path = SECOND_DATASET_TRAIN_DIR / f\"{image_id}{ext}\"\n",
        "                if potential_path.exists():\n",
        "                    image_path = potential_path\n",
        "                    break\n",
        "            \n",
        "            if image_path and image_path.exists():\n",
        "                try:\n",
        "                    img = Image.open(image_path)\n",
        "                    # Handle palette images\n",
        "                    if img.mode == 'P':\n",
        "                        img = img.convert('RGBA')\n",
        "                    if img.mode == 'RGBA':\n",
        "                        background = Image.new('RGB', img.size, (255, 255, 255))\n",
        "                        background.paste(img, mask=img.split()[3])\n",
        "                        img = background\n",
        "                    elif img.mode != 'RGB':\n",
        "                        img = img.convert('RGB')\n",
        "                    \n",
        "                    axes[label_idx, sample_idx].imshow(img)\n",
        "                    axes[label_idx, sample_idx].set_title(f\"{label}\\nID: {image_id}\\n{row['width']}x{row['height']}\", \n",
        "                                                       fontsize=10)\n",
        "                    axes[label_idx, sample_idx].axis('off')\n",
        "                except Exception as e:\n",
        "                    axes[label_idx, sample_idx].text(0.5, 0.5, f\"Error\\nloading\\nimage\", \n",
        "                                                    ha='center', va='center', transform=axes[label_idx, sample_idx].transAxes)\n",
        "                    axes[label_idx, sample_idx].axis('off')\n",
        "            else:\n",
        "                axes[label_idx, sample_idx].text(0.5, 0.5, f\"Image\\nnot found\", \n",
        "                                                ha='center', va='center', transform=axes[label_idx, sample_idx].transAxes)\n",
        "                axes[label_idx, sample_idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(f\"\\nDisplayed {n_samples_per_label} sample images per label\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary Statistics and Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_df is not None and len(image_df) > 0:\n",
        "    print(\"=\"*70)\n",
        "    print(\"DATASET SUMMARY STATISTICS\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    print(f\"\\nTotal Images: {len(image_df)}\")\n",
        "    print(f\"Unique Labels: {len(image_df['label'].unique())}\")\n",
        "    print(f\"Labels: {', '.join(sorted(image_df['label'].unique()))}\")\n",
        "    \n",
        "    print(f\"\\n\" + \"-\"*70)\n",
        "    print(\"Image Size Statistics:\")\n",
        "    print(f\"  Width:  {image_df['width'].min()} - {image_df['width'].max()} (mean: {image_df['width'].mean():.1f})\")\n",
        "    print(f\"  Height: {image_df['height'].min()} - {image_df['height'].max()} (mean: {image_df['height'].mean():.1f})\")\n",
        "    print(f\"  Aspect Ratio: {image_df['aspect_ratio'].min():.2f} - {image_df['aspect_ratio'].max():.2f} (mean: {image_df['aspect_ratio'].mean():.2f})\")\n",
        "    \n",
        "    print(f\"\\n\" + \"-\"*70)\n",
        "    print(\"Color Statistics:\")\n",
        "    print(f\"  Mean Brightness: {image_df['brightness'].min():.1f} - {image_df['brightness'].max():.1f} (mean: {image_df['brightness'].mean():.1f})\")\n",
        "    print(f\"  Mostly White Images: {image_df['is_mostly_white'].sum()} ({image_df['is_mostly_white'].mean()*100:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\n\" + \"-\"*70)\n",
        "    print(\"Image Mode Distribution:\")\n",
        "    for mode, count in image_df['original_mode'].value_counts().items():\n",
        "        print(f\"  {mode}: {count} ({count/len(image_df)*100:.1f}%)\")\n",
        "    \n",
        "    print(f\"\\n\" + \"-\"*70)\n",
        "    print(\"Label Distribution:\")\n",
        "    label_counts = image_df['label'].value_counts()\n",
        "    for label, count in label_counts.items():\n",
        "        print(f\"  {label:15s}: {count:4d} ({count/len(image_df)*100:5.1f}%)\")\n",
        "    \n",
        "    print(f\"\\n\" + \"-\"*70)\n",
        "    print(\"Key Insights:\")\n",
        "    \n",
        "    # Check if image properties are predictive\n",
        "    if image_df['image_id_numeric'].notna().any():\n",
        "        id_overlap = False\n",
        "        label_ranges = {}\n",
        "        for label in image_df['label'].unique():\n",
        "            label_data = image_df[(image_df['label'] == label) & (image_df['image_id_numeric'].notna())]\n",
        "            if len(label_data) > 0:\n",
        "                label_ranges[label] = (label_data['image_id_numeric'].min(), label_data['image_id_numeric'].max())\n",
        "        \n",
        "        # Check for overlapping ranges\n",
        "        ranges_list = list(label_ranges.values())\n",
        "        for i, (min1, max1) in enumerate(ranges_list):\n",
        "            for j, (min2, max2) in enumerate(ranges_list[i+1:], i+1):\n",
        "                if not (max1 < min2 or max2 < min1):\n",
        "                    id_overlap = True\n",
        "                    break\n",
        "        \n",
        "        if not id_overlap:\n",
        "            print(\"  ⚠️  Image IDs appear to be NON-OVERLAPPING by label - IDs might be predictive!\")\n",
        "        else:\n",
        "            print(\"  ✓ Image ID ranges overlap between labels - IDs are not clearly predictive\")\n",
        "    \n",
        "    # Check size consistency\n",
        "    size_std = image_df.groupby('label')[['width', 'height']].std().mean().mean()\n",
        "    if size_std < 10:\n",
        "        print(f\"  ⚠️  Images have very consistent sizes (std: {size_std:.1f}) - size might be predictive\")\n",
        "    else:\n",
        "        print(f\"  ✓ Images have variable sizes (std: {size_std:.1f}) - size is less predictive\")\n",
        "    \n",
        "    # Check color differences\n",
        "    color_diff = image_df.groupby('label')['brightness'].mean().std()\n",
        "    if color_diff > 20:\n",
        "        print(f\"  ⚠️  Labels have different average brightness (std: {color_diff:.1f}) - color might be predictive\")\n",
        "    else:\n",
        "        print(f\"  ✓ Labels have similar brightness (std: {color_diff:.1f}) - color is less predictive\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
